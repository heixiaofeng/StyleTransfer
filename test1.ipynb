{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_weight_bias(vgg_layers, i):\n",
    "    weights = vgg_layers[i][0][0][0][0][0]\n",
    "    weights = tf.constant(weights)\n",
    "\n",
    "    bias = vgg_layers[i][0][0][0][0][1]\n",
    "    bias = tf.constant(np.reshape(bias, (bias.size)))\n",
    "    return weights, bias\n",
    "\n",
    "def build_net(layer_name,inputs,nwb=None):\n",
    "    # net_type 需要定义网络层的名字\n",
    "    if layer_name == 'conv':\n",
    "        out = tf.nn.relu(tf.add(tf.nn.conv2d(inputs,nwb[0],[1,1,1,1],'SAME'),nwb[1]))\n",
    "    elif layer_name == 'pool':\n",
    "        out = tf.nn.max_pool(inputs,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def bulit_vgg19(path,image_shape):\n",
    "    net = {}\n",
    "    vgg_rawnet = loadmat(path)\n",
    "    vgg_layers = vgg_rawnet['layers'][0]\n",
    "    net['input'] = tf.Variable(np.zeros(image_shape).astype('float32'))\n",
    "    net['conv1_1'] = build_net('conv', net['input'], get_weight_bias(vgg_layers, 0))\n",
    "    net['conv1_2'] = build_net('conv', net['conv1_1'], get_weight_bias(vgg_layers, 2))\n",
    "    net['pool1'] = build_net('pool', net['conv1_2'])\n",
    "    net['conv2_1'] = build_net('conv', net['pool1'], get_weight_bias(vgg_layers, 5))\n",
    "    net['conv2_2'] = build_net('conv', net['conv2_1'], get_weight_bias(vgg_layers, 7))\n",
    "    net['pool2'] = build_net('pool', net['conv2_2'])\n",
    "\n",
    "    net['conv3_1'] = build_net('conv', net['pool2'], get_weight_bias(vgg_layers, 10))\n",
    "    net['conv3_2'] = build_net('conv', net['conv3_1'], get_weight_bias(vgg_layers, 12))\n",
    "    net['conv3_3'] = build_net('conv', net['conv3_2'], get_weight_bias(vgg_layers, 14))\n",
    "    net['conv3_4'] = build_net('conv', net['conv3_3'], get_weight_bias(vgg_layers, 16))\n",
    "    net['pool3'] = build_net('pool', net['conv3_4'])\n",
    "\n",
    "    net['conv4_1'] = build_net('conv', net['pool3'], get_weight_bias(vgg_layers, 19))\n",
    "    net['conv4_2'] = build_net('conv', net['conv4_1'], get_weight_bias(vgg_layers, 21))\n",
    "    net['conv4_3'] = build_net('conv', net['conv4_2'], get_weight_bias(vgg_layers, 23))\n",
    "    net['conv4_4'] = build_net('conv', net['conv4_3'], get_weight_bias(vgg_layers, 25))\n",
    "    net['pool4'] = build_net('pool', net['conv4_4'])\n",
    "\n",
    "    net['conv5_1'] = build_net('conv', net['pool4'], get_weight_bias(vgg_layers, 28))\n",
    "    net['conv5_2'] = build_net('conv', net['conv5_1'], get_weight_bias(vgg_layers, 30))\n",
    "    net['conv5_3'] = build_net('conv', net['conv5_2'], get_weight_bias(vgg_layers, 32))\n",
    "    net['conv5_4'] = build_net('conv', net['conv5_3'], get_weight_bias(vgg_layers, 34))\n",
    "    net['pool5'] = build_net('pool', net['conv5_4'])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "mean = np.array([[[[123.68, 116.779, 103.939]]]])\n",
    "def save_image(img,path,iter):\n",
    "    image = img+mean\n",
    "    image = np.squeeze(image,0)\n",
    "    image = image.astype('uint8')\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(path+'gen%d'%iter+'.png',format='png')\n",
    "\n",
    "\n",
    "def load_images(path,img_shape):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((img_shape[1], img_shape[2]))\n",
    "    img = np.asarray(img)\n",
    "    img = img[np.newaxis,:]\n",
    "    img = img - mean\n",
    "    return img\n",
    "\n",
    "\n",
    "def gen_noise_img(image_shape,content_image,noise_ratio=0.6):\n",
    "\n",
    "    noise_img = np.random.uniform(-10,10,image_shape)\n",
    "    noise_img = noise_img*noise_ratio + content_image*(1 - noise_ratio)\n",
    "\n",
    "    return noise_img\n",
    "\n",
    "def content_loss(layer_name,sess,net):\n",
    "    p = sess.run(net[layer_name])\n",
    "    x = net[layer_name]\n",
    "    loss = 0.5*tf.reduce_sum(tf.pow((p-x),2))\n",
    "    return loss\n",
    "\n",
    "def gram_matrix(x):\n",
    "    M = x.shape[1] * x.shape[2]\n",
    "    N = x.shape[3]\n",
    "    g = tf.reshape(x,[-1,N])\n",
    "    G = tf.matmul(tf.transpose(g),g)\n",
    "    return G\n",
    "\n",
    "\n",
    "def count_style_loss(g,a):\n",
    "    M = g.shape[1]*g.shape[2]\n",
    "    N = g.shape[3]\n",
    "    A = gram_matrix(a)\n",
    "    G = gram_matrix(g)\n",
    "    return 1/(4*N**2*M**2)*tf.reduce_sum(tf.pow((G-A),2))\n",
    "\n",
    "def style_loss(layers,sess,net):\n",
    "    loss = 0\n",
    "    for layer in layers:\n",
    "        g = sess.run(net[layer])\n",
    "        a = net[layer]\n",
    "\n",
    "        loss += count_style_loss(g,a)\n",
    "    return loss/len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have save 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "\n",
    "vgg_weight_path = 'imagenet-vgg-verydeep-19.mat'\n",
    "save_img_path = './out'\n",
    "\n",
    "image_shape = [1,512,512,3]\n",
    "\n",
    "style_pic_path = './styles/star.jpg'\n",
    "content_pic_path = './pic/scene.jpg'\n",
    "content_layer = 'conv4_2'\n",
    "style_layer = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "\n",
    "alpha = 1\n",
    "beta = 300\n",
    "lr = 1\n",
    "iterations = 1000\n",
    "\n",
    "\n",
    "style_img = load_images(style_pic_path,image_shape)\n",
    "content_img =load_images(content_pic_path,image_shape)\n",
    "\n",
    "gen_img = gen_noise_img(image_shape,content_img,noise_ratio=0.6)\n",
    "\n",
    "vgg_net = bulit_vgg19(vgg_weight_path,image_shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run([vgg_net['input'].assign(content_img)])\n",
    "loss_content = content_loss(content_layer,sess,vgg_net)\n",
    "\n",
    "\n",
    "sess.run(vgg_net['input'].assign(style_img))\n",
    "loss_style = style_loss(style_layer,sess,vgg_net)\n",
    "\n",
    "total_loss = alpha*loss_content+beta*loss_style\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(total_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(vgg_net['input'].assign(gen_img))\n",
    "\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        sess.run(optimizer)\n",
    "\n",
    "        if iter%100 == 0:\n",
    "            gen_pic = sess.run(vgg_net['input'])\n",
    "            gen_pic = gen_pic\n",
    "            save_image(gen_pic,save_img_path,iter)\n",
    "\n",
    "            print('have save %d' % (iter / 100 + 1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
